{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6732290-95ee-404b-98cf-01253223c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c2b1a6-3b60-4716-87b0-55dcd20a7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nlp('3D model visualises what an asteroid hitting Earth in 2032 would look like. If Asteroid 2024 YR4 were to strike Earth, the energy released could be equivalent to 8 megatons of TNT, capable of devastating an area the size of Washington, D.C. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97e3690c-48b3-4399-9deb-fcf00da324b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D -- ADJ --  adjective ++==> JJ --> adjective (English), other noun-modifier (Chinese)\n",
      "model -- NOUN --  noun ++==> NN --> noun, singular or mass\n",
      "visualises -- VERB --  verb ++==> VBZ --> verb, 3rd person singular present\n",
      "what -- PRON --  pronoun ++==> WP --> wh-pronoun, personal\n",
      "an -- DET --  determiner ++==> DT --> determiner\n",
      "asteroid -- NOUN --  noun ++==> NN --> noun, singular or mass\n",
      "hitting -- VERB --  verb ++==> VBG --> verb, gerund or present participle\n",
      "Earth -- PROPN --  proper noun ++==> NNP --> noun, proper singular\n",
      "in -- ADP --  adposition ++==> IN --> conjunction, subordinating or preposition\n",
      "2032 -- NUM --  numeral ++==> CD --> cardinal number\n",
      "would -- AUX --  auxiliary ++==> MD --> verb, modal auxiliary\n",
      "look -- VERB --  verb ++==> VB --> verb, base form\n",
      "like -- ADP --  adposition ++==> IN --> conjunction, subordinating or preposition\n",
      ". -- PUNCT --  punctuation ++==> . --> punctuation mark, sentence closer\n",
      "If -- SCONJ --  subordinating conjunction ++==> IN --> conjunction, subordinating or preposition\n",
      "Asteroid -- PROPN --  proper noun ++==> NNP --> noun, proper singular\n",
      "2024 -- NUM --  numeral ++==> CD --> cardinal number\n",
      "YR4 -- PROPN --  proper noun ++==> NNP --> noun, proper singular\n",
      "were -- AUX --  auxiliary ++==> VBD --> verb, past tense\n",
      "to -- PART --  particle ++==> TO --> infinitival \"to\"\n",
      "strike -- VERB --  verb ++==> VB --> verb, base form\n",
      "Earth -- PROPN --  proper noun ++==> NNP --> noun, proper singular\n",
      ", -- PUNCT --  punctuation ++==> , --> punctuation mark, comma\n",
      "the -- DET --  determiner ++==> DT --> determiner\n",
      "energy -- NOUN --  noun ++==> NN --> noun, singular or mass\n",
      "released -- VERB --  verb ++==> VBN --> verb, past participle\n",
      "could -- AUX --  auxiliary ++==> MD --> verb, modal auxiliary\n",
      "be -- AUX --  auxiliary ++==> VB --> verb, base form\n",
      "equivalent -- ADJ --  adjective ++==> JJ --> adjective (English), other noun-modifier (Chinese)\n",
      "to -- ADP --  adposition ++==> IN --> conjunction, subordinating or preposition\n",
      "8 -- NUM --  numeral ++==> CD --> cardinal number\n",
      "megatons -- NOUN --  noun ++==> NNS --> noun, plural\n",
      "of -- ADP --  adposition ++==> IN --> conjunction, subordinating or preposition\n",
      "TNT -- PROPN --  proper noun ++==> NNP --> noun, proper singular\n",
      ", -- PUNCT --  punctuation ++==> , --> punctuation mark, comma\n",
      "capable -- ADJ --  adjective ++==> JJ --> adjective (English), other noun-modifier (Chinese)\n",
      "of -- ADP --  adposition ++==> IN --> conjunction, subordinating or preposition\n",
      "devastating -- VERB --  verb ++==> VBG --> verb, gerund or present participle\n",
      "an -- DET --  determiner ++==> DT --> determiner\n",
      "area -- NOUN --  noun ++==> NN --> noun, singular or mass\n",
      "the -- DET --  determiner ++==> DT --> determiner\n",
      "size -- NOUN --  noun ++==> NN --> noun, singular or mass\n",
      "of -- ADP --  adposition ++==> IN --> conjunction, subordinating or preposition\n",
      "Washington -- PROPN --  proper noun ++==> NNP --> noun, proper singular\n",
      ", -- PUNCT --  punctuation ++==> , --> punctuation mark, comma\n",
      "D.C. -- PROPN --  proper noun ++==> NNP --> noun, proper singular\n"
     ]
    }
   ],
   "source": [
    "for token in text:\n",
    "    print(token, '--' , token.pos_ , '-- ', spacy.explain(token.pos_),'++==>', token.tag_, '-->' ,spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4e06991-f8c0-473b-8c0e-24fe7b6c5fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D -- JJ --> adjective (English), other noun-modifier (Chinese)\n",
      "model -- NN --> noun, singular or mass\n",
      "visualises -- VBZ --> verb, 3rd person singular present\n",
      "what -- WP --> wh-pronoun, personal\n",
      "an -- DT --> determiner\n",
      "asteroid -- NN --> noun, singular or mass\n",
      "hitting -- VBG --> verb, gerund or present participle\n",
      "Earth -- NNP --> noun, proper singular\n",
      "in -- IN --> conjunction, subordinating or preposition\n",
      "2032 -- CD --> cardinal number\n",
      "would -- MD --> verb, modal auxiliary\n",
      "look -- VB --> verb, base form\n",
      "like -- IN --> conjunction, subordinating or preposition\n",
      ". -- . --> punctuation mark, sentence closer\n",
      "If -- IN --> conjunction, subordinating or preposition\n",
      "Asteroid -- NNP --> noun, proper singular\n",
      "2024 -- CD --> cardinal number\n",
      "YR4 -- NNP --> noun, proper singular\n",
      "were -- VBD --> verb, past tense\n",
      "to -- TO --> infinitival \"to\"\n",
      "strike -- VB --> verb, base form\n",
      "Earth -- NNP --> noun, proper singular\n",
      ", -- , --> punctuation mark, comma\n",
      "the -- DT --> determiner\n",
      "energy -- NN --> noun, singular or mass\n",
      "released -- VBN --> verb, past participle\n",
      "could -- MD --> verb, modal auxiliary\n",
      "be -- VB --> verb, base form\n",
      "equivalent -- JJ --> adjective (English), other noun-modifier (Chinese)\n",
      "to -- IN --> conjunction, subordinating or preposition\n",
      "8 -- CD --> cardinal number\n",
      "megatons -- NNS --> noun, plural\n",
      "of -- IN --> conjunction, subordinating or preposition\n",
      "TNT -- NNP --> noun, proper singular\n",
      ", -- , --> punctuation mark, comma\n",
      "capable -- JJ --> adjective (English), other noun-modifier (Chinese)\n",
      "of -- IN --> conjunction, subordinating or preposition\n",
      "devastating -- VBG --> verb, gerund or present participle\n",
      "an -- DT --> determiner\n",
      "area -- NN --> noun, singular or mass\n",
      "the -- DT --> determiner\n",
      "size -- NN --> noun, singular or mass\n",
      "of -- IN --> conjunction, subordinating or preposition\n",
      "Washington -- NNP --> noun, proper singular\n",
      ", -- , --> punctuation mark, comma\n",
      "D.C. -- NNP --> noun, proper singular\n"
     ]
    }
   ],
   "source": [
    "for token in text:\n",
    "    print(token, '--' ,  token.tag_, '-->' ,spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "701ce374-1d3b-4145-b9b9-2b61927dffe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3D model visualises what an asteroid hitting Earth in 2032 would look like. If Asteroid 2024 YR4 were to strike Earth, the energy released could be equivalent to 8 megatons of TNT, capable of devastating an area the size of Washington, D.C. "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e3f903f-3d26-4ed6-8747-c1526274550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nlp('''Techie's first bold career in 2025 switch slashed her pay by 40% to $700000, now she’s living her dream in Mumbai with a job at Meta''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c4ef0ad-1e40-4569-826c-f842ec54d7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Techie -- PERSON -- People, including fictional\n",
      "first -- ORDINAL -- \"first\", \"second\", etc.\n",
      "2025 -- DATE -- Absolute or relative dates or periods\n",
      "40% -- PERCENT -- Percentage, including \"%\"\n",
      "700000 -- MONEY -- Monetary values, including unit\n",
      "Mumbai -- GPE -- Countries, cities, states\n",
      "Meta -- ORG -- Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "for ent in text.ents:\n",
    "    print(ent.text, '--', ent.label_, '--' ,spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93deba82-939c-4931-8e85-226d114a75f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CARDINAL',\n",
       " 'DATE',\n",
       " 'EVENT',\n",
       " 'FAC',\n",
       " 'GPE',\n",
       " 'LANGUAGE',\n",
       " 'LAW',\n",
       " 'LOC',\n",
       " 'MONEY',\n",
       " 'NORP',\n",
       " 'ORDINAL',\n",
       " 'ORG',\n",
       " 'PERCENT',\n",
       " 'PERSON',\n",
       " 'PRODUCT',\n",
       " 'QUANTITY',\n",
       " 'TIME',\n",
       " 'WORK_OF_ART']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_labels['ner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ece98677-5bf3-41b5-b3e5-441af54f5a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3487e896-1ac8-4d12-9e9b-e3e49dd5b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c30fb08-a26c-4068-977c-789f4361a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nlp('''OpenAI CEO Sam Altman said on social media last week that saying \"please\" and \"thank you\" to ChatGPT has cost the company quite a bit of money.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b84b79c-b559-454a-b4a1-9b782caa2964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI  --  False\n",
      "CEO  --  False\n",
      "Sam  --  False\n",
      "Altman  --  False\n",
      "said  --  False\n",
      "on  --  True\n",
      "social  --  False\n",
      "media  --  False\n",
      "last  --  True\n",
      "week  --  False\n",
      "that  --  True\n",
      "saying  --  False\n",
      "\"  --  False\n",
      "please  --  True\n",
      "\"  --  False\n",
      "and  --  True\n",
      "\"  --  False\n",
      "thank  --  False\n",
      "you  --  True\n",
      "\"  --  False\n",
      "to  --  True\n",
      "ChatGPT  --  False\n",
      "has  --  True\n",
      "cost  --  False\n",
      "the  --  True\n",
      "company  --  False\n",
      "quite  --  True\n",
      "a  --  True\n",
      "bit  --  False\n",
      "of  --  True\n",
      "money  --  False\n",
      ".  --  False\n"
     ]
    }
   ],
   "source": [
    "for token in text:\n",
    "    print(token, ' -- ' ,token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fcc6081e-9fb0-4cf5-ab79-72ec7e4cd5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on\n",
      "last\n",
      "that\n",
      "please\n",
      "and\n",
      "you\n",
      "to\n",
      "has\n",
      "the\n",
      "quite\n",
      "a\n",
      "of\n"
     ]
    }
   ],
   "source": [
    "for token in text:\n",
    "    if token.is_stop:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ae6237b-1867-4ce0-80ae-4b79cb35c8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_dep',\n",
       " 'has_extension',\n",
       " 'has_head',\n",
       " 'has_morph',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'iob_strings',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_end',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'set_morph',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "933bf2ac-7d1f-43e4-a9ff-3e7e30a18dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'could',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " \"n't\",\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'n‘t',\n",
       " 'n’t',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'regarding',\n",
       " 'same',\n",
       " 'say',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'under',\n",
       " 'unless',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " '‘d',\n",
       " '‘ll',\n",
       " '‘m',\n",
       " '‘re',\n",
       " '‘s',\n",
       " '‘ve',\n",
       " '’d',\n",
       " '’ll',\n",
       " '’m',\n",
       " '’re',\n",
       " '’s',\n",
       " '’ve'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c69c869-bee5-4078-9944-69ea91b793a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nlp('''I am Nashit. I am from Patna. I am an engineer. I'll be working again''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5238aea4-8644-4490-969b-65da87b08055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "I\n",
      "am\n",
      "from\n",
      "I\n",
      "am\n",
      "an\n",
      "I\n",
      "'ll\n",
      "be\n",
      "again\n"
     ]
    }
   ],
   "source": [
    "for token in text:\n",
    "    if token.is_stop:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01d2f3de-de2c-402b-9b63-9d359bf4d86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I --  True\n",
      "am --  True\n",
      "Nashit --  False\n",
      ". --  False\n",
      "I --  True\n",
      "am --  True\n",
      "from --  True\n",
      "Patna --  False\n",
      ". --  False\n",
      "I --  True\n",
      "am --  True\n",
      "an --  True\n",
      "engineer --  False\n",
      ". --  False\n",
      "I --  True\n",
      "'ll --  True\n",
      "be --  True\n",
      "working --  False\n",
      "again --  True\n"
     ]
    }
   ],
   "source": [
    "for token in text:\n",
    "    print(token, '-- ', token.is_stop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c14dc2a-90be-4181-9405-89946bc74055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLTK - Natural Language Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aefdc6b-a6b5-4930-a06d-691c2a8df366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b97cef57-a2a6-465d-86e4-410388b3cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "521d3055-cd67-471d-b559-9a7b04eceeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8a99e6c-7d64-46a8-ba01-96195b6e6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nlp('I am Nashit. I am from Patna. I love development. I love food.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4de590db-79a4-4396-bb79-ce2fb9cfc0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am Nashit.\n",
      "I am from Patna.\n",
      "I love development.\n",
      "I love food.\n"
     ]
    }
   ],
   "source": [
    "for i in text.sents:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e016e2c0-9b19-4882-bada-3f15fbd87048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "Nashit\n",
      ".\n",
      "I\n",
      "am\n",
      "from\n",
      "Patna\n",
      ".\n",
      "I\n",
      "love\n",
      "development\n",
      ".\n",
      "I\n",
      "love\n",
      "food\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for sent in text.sents:\n",
    "    for word in sent:\n",
    "        print(word)\n",
    "    # print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7940ad64-fd31-400c-866e-5c6b3cd085b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ca70b16-88a1-4634-a2a0-7505cc29f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d18d75b5-c544-4cf7-96db-bbee4a1b724d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\s_nas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\s_nas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a42e971e-53c1-4f32-aaff-c156ea5f0537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am Nashit.', 'I am from Patna.', 'I love development.', 'I love food.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize('I am Nashit. I am from Patna. I love development. I love food.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2aa75f2-c4b6-4ea2-a3cf-c11275168193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04a292ff-2912-474c-bff6-18df12f4b1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'Nashit',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'from',\n",
       " 'Patna',\n",
       " '.',\n",
       " 'I',\n",
       " 'love',\n",
       " 'development',\n",
       " '.',\n",
       " 'I',\n",
       " 'love',\n",
       " 'food',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('I am Nashit. I am from Patna. I love development. I love food.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09f70ba1-f615-4a3f-86be-97ae407d6563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "Nashit\n",
      ".\n",
      "I\n",
      "am\n",
      "from\n",
      "Patna\n",
      ".\n",
      "I\n",
      "love\n",
      "development\n",
      ".\n",
      "I\n",
      "love\n",
      "food\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in text:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a2e95e2-1c6b-4346-8696-da7a07b0bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_c = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbe8347a-f050-4c62-aa52-d2a5ed7c4bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nlp('200@abc.com I am Nashit. hello.com I am from Patna. I love development. I love food.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd0ad494-9f8d-493d-a949-3bb97272df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in text:\n",
    "   # print(token)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffa26a51-2d1a-47bd-a962-ebb51af10ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c10bec8f-1692-41d5-8a66-ef4f633419f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200@abc.com"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5fbb0d2-32aa-4fd9-b35a-4aa3cb6f7d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_dep',\n",
       " 'has_extension',\n",
       " 'has_head',\n",
       " 'has_morph',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'iob_strings',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_end',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'set_morph',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecfff75c-fb7d-40ed-acb5-6554677f27c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b265925-7200-4088-8537-dfbc5816bc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0.like_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c47591d-3a51-4b58-9ac6-8a4a29760fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  |  200@abc.com | True | False | False , False\n",
      "1  |  I | False | False | False , False\n",
      "2  |  am | True | False | False , False\n",
      "3  |  Nashit | False | False | False , False\n",
      "4  |  . | False | False | True , False\n",
      "5  |  hello.com | True | False | False , True\n",
      "6  |  I | False | False | False , False\n",
      "7  |  am | True | False | False , False\n",
      "8  |  from | True | False | False , False\n",
      "9  |  Patna | False | False | False , False\n",
      "10  |  . | False | False | True , False\n",
      "11  |  I | False | False | False , False\n",
      "12  |  love | True | False | False , False\n",
      "13  |  development | True | False | False , False\n",
      "14  |  . | False | False | True , False\n",
      "15  |  I | False | False | False , False\n",
      "16  |  love | True | False | False , False\n",
      "17  |  food | True | False | False , False\n",
      "18  |  . | False | False | True , False\n"
     ]
    }
   ],
   "source": [
    "for token in text:\n",
    "    print(token.i, ' | ', token, '|', token.is_lower, '|', token.is_right_punct, '|', token.is_punct, ',', token.like_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92632f79-4554-483b-87b8-06937e55c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84eda8ef-0c5a-4bb9-a0c3-5779899d7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_h = spacy.blank('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aca85671-7580-493a-a29a-f86198f28a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nlp_h('₹ 200 अनुवाद एक मुफ्त ऑनलाइन सेवा है जो ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9517df6d-4b39-4983-a380-5418f9bef7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "₹ | False False True\n",
      "200 | False True False\n",
      "अनुवाद | False False False\n",
      "एक | False True False\n",
      "मुफ्त | False False False\n",
      "ऑनलाइन | False False False\n",
      "सेवा | False False False\n",
      "है | False False False\n",
      "जो | False False False\n"
     ]
    }
   ],
   "source": [
    "for token in text:\n",
    "    print(token, \"|\", token.is_punct, token.like_num, token.is_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ba5d01b8-2fc7-4987-bc24-b9f7b849538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_h.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50b072e6-dce0-492f-9205-ec993bcff360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_c.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6cd1a735-4d2c-4632-9be0-c30db4cbbb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1fd3a6bed50>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1fd3a6bfd70>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1fd51c95000>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x1fd3b291350>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1fd3b297e50>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1fd51c94e40>)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_c.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7887fdd3-822f-41d2-a03a-37690af7fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nlp_c('A hilariously honest resignation email has taken the internet by storm after it was shared by Shubham Gune, founder and CEO of Hinglish, on LinkedIn. The brief message from an employee named Dayitva Shah simply read: “Hi sir, mai bik gaya, samne wali company 4 paisa jada de rahi hai (Hi sir, I’ve sold out, the other company is offering a little more money). Regards, Dayitva Shah.” The straightforward confession, loosely translated as “I’ve sold out, the other company is offering a bit more money,” struck a chord with thousands online. While many laughed at the blunt tone, others saw it as a reflection of real frustrations in today’s job market.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fd25246e-bf14-44eb-8b27-43437ebc6177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A | DET -- determiner  |  a\n",
      "hilariously | ADV -- adverb  |  hilariously\n",
      "honest | ADJ -- adjective  |  honest\n",
      "resignation | NOUN -- noun  |  resignation\n",
      "email | NOUN -- noun  |  email\n",
      "has | AUX -- auxiliary  |  have\n",
      "taken | VERB -- verb  |  take\n",
      "the | DET -- determiner  |  the\n",
      "internet | NOUN -- noun  |  internet\n",
      "by | ADP -- adposition  |  by\n",
      "storm | NOUN -- noun  |  storm\n",
      "after | SCONJ -- subordinating conjunction  |  after\n",
      "it | PRON -- pronoun  |  it\n",
      "was | AUX -- auxiliary  |  be\n",
      "shared | VERB -- verb  |  share\n",
      "by | ADP -- adposition  |  by\n",
      "Shubham | PROPN -- proper noun  |  Shubham\n",
      "Gune | PROPN -- proper noun  |  Gune\n",
      ", | PUNCT -- punctuation  |  ,\n",
      "founder | NOUN -- noun  |  founder\n",
      "and | CCONJ -- coordinating conjunction  |  and\n",
      "CEO | NOUN -- noun  |  ceo\n",
      "of | ADP -- adposition  |  of\n",
      "Hinglish | PROPN -- proper noun  |  Hinglish\n",
      ", | PUNCT -- punctuation  |  ,\n",
      "on | ADP -- adposition  |  on\n",
      "LinkedIn | PROPN -- proper noun  |  LinkedIn\n",
      ". | PUNCT -- punctuation  |  .\n",
      "The | DET -- determiner  |  the\n",
      "brief | ADJ -- adjective  |  brief\n",
      "message | NOUN -- noun  |  message\n",
      "from | ADP -- adposition  |  from\n",
      "an | DET -- determiner  |  an\n",
      "employee | NOUN -- noun  |  employee\n",
      "named | VERB -- verb  |  name\n",
      "Dayitva | PROPN -- proper noun  |  Dayitva\n",
      "Shah | PROPN -- proper noun  |  Shah\n",
      "simply | ADV -- adverb  |  simply\n",
      "read | VERB -- verb  |  read\n",
      ": | PUNCT -- punctuation  |  :\n",
      "“ | PUNCT -- punctuation  |  \"\n",
      "Hi | INTJ -- interjection  |  hi\n",
      "sir | NOUN -- noun  |  sir\n",
      ", | PUNCT -- punctuation  |  ,\n",
      "mai | PROPN -- proper noun  |  mai\n",
      "bik | PROPN -- proper noun  |  bik\n",
      "gaya | PROPN -- proper noun  |  gaya\n",
      ", | PUNCT -- punctuation  |  ,\n",
      "samne | PROPN -- proper noun  |  samne\n",
      "wali | PROPN -- proper noun  |  wali\n",
      "company | PROPN -- proper noun  |  company\n",
      "4 | NUM -- numeral  |  4\n",
      "paisa | NOUN -- noun  |  paisa\n",
      "jada | PROPN -- proper noun  |  jada\n",
      "de | PROPN -- proper noun  |  de\n",
      "rahi | PROPN -- proper noun  |  rahi\n",
      "hai | PROPN -- proper noun  |  hai\n",
      "( | PUNCT -- punctuation  |  (\n",
      "Hi | PROPN -- proper noun  |  Hi\n",
      "sir | NOUN -- noun  |  sir\n",
      ", | PUNCT -- punctuation  |  ,\n",
      "I | PRON -- pronoun  |  I\n",
      "’ve | AUX -- auxiliary  |  ’ve\n",
      "sold | VERB -- verb  |  sell\n",
      "out | ADP -- adposition  |  out\n",
      ", | PUNCT -- punctuation  |  ,\n",
      "the | DET -- determiner  |  the\n",
      "other | ADJ -- adjective  |  other\n",
      "company | NOUN -- noun  |  company\n",
      "is | AUX -- auxiliary  |  be\n",
      "offering | VERB -- verb  |  offer\n",
      "a | DET -- determiner  |  a\n",
      "little | ADJ -- adjective  |  little\n",
      "more | ADJ -- adjective  |  more\n",
      "money | NOUN -- noun  |  money\n",
      ") | PUNCT -- punctuation  |  )\n",
      ". | PUNCT -- punctuation  |  .\n",
      "Regards | NOUN -- noun  |  regard\n",
      ", | PUNCT -- punctuation  |  ,\n",
      "Dayitva | PROPN -- proper noun  |  Dayitva\n",
      "Shah | PROPN -- proper noun  |  Shah\n",
      ". | PUNCT -- punctuation  |  .\n",
      "” | PUNCT -- punctuation  |  \"\n",
      "The | DET -- determiner  |  the\n",
      "straightforward | ADJ -- adjective  |  straightforward\n",
      "confession | NOUN -- noun  |  confession\n",
      ", | PUNCT -- punctuation  |  ,\n",
      "loosely | ADV -- adverb  |  loosely\n",
      "translated | VERB -- verb  |  translate\n",
      "as | SCONJ -- subordinating conjunction  |  as\n",
      "“ | PUNCT -- punctuation  |  \"\n",
      "I | PRON -- pronoun  |  I\n",
      "’ve | AUX -- auxiliary  |  ’ve\n",
      "sold | VERB -- verb  |  sell\n",
      "out | ADP -- adposition  |  out\n",
      ", | PUNCT -- punctuation  |  ,\n",
      "the | DET -- determiner  |  the\n",
      "other | ADJ -- adjective  |  other\n",
      "company | NOUN -- noun  |  company\n",
      "is | AUX -- auxiliary  |  be\n",
      "offering | VERB -- verb  |  offer\n",
      "a | DET -- determiner  |  a\n",
      "bit | NOUN -- noun  |  bit\n",
      "more | ADJ -- adjective  |  more\n",
      "money | NOUN -- noun  |  money\n",
      ", | PUNCT -- punctuation  |  ,\n",
      "” | PUNCT -- punctuation  |  \"\n",
      "struck | VERB -- verb  |  strike\n",
      "a | DET -- determiner  |  a\n",
      "chord | NOUN -- noun  |  chord\n",
      "with | ADP -- adposition  |  with\n",
      "thousands | NOUN -- noun  |  thousand\n",
      "online | ADV -- adverb  |  online\n",
      ". | PUNCT -- punctuation  |  .\n",
      "While | SCONJ -- subordinating conjunction  |  while\n",
      "many | ADJ -- adjective  |  many\n",
      "laughed | VERB -- verb  |  laugh\n",
      "at | ADP -- adposition  |  at\n",
      "the | DET -- determiner  |  the\n",
      "blunt | ADJ -- adjective  |  blunt\n",
      "tone | NOUN -- noun  |  tone\n",
      ", | PUNCT -- punctuation  |  ,\n",
      "others | NOUN -- noun  |  other\n",
      "saw | VERB -- verb  |  see\n",
      "it | PRON -- pronoun  |  it\n",
      "as | ADP -- adposition  |  as\n",
      "a | DET -- determiner  |  a\n",
      "reflection | NOUN -- noun  |  reflection\n",
      "of | ADP -- adposition  |  of\n",
      "real | ADJ -- adjective  |  real\n",
      "frustrations | NOUN -- noun  |  frustration\n",
      "in | ADP -- adposition  |  in\n",
      "today | NOUN -- noun  |  today\n",
      "’s | PART -- particle  |  ’s\n",
      "job | NOUN -- noun  |  job\n",
      "market | NOUN -- noun  |  market\n",
      ". | PUNCT -- punctuation  |  .\n"
     ]
    }
   ],
   "source": [
    "for token in text:\n",
    "    print(token,  '|', token.pos_ , '--' , spacy.explain(token.pos_), ' | ',  token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fb2efc04-9fcb-410c-9395-1e5f98cdf7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1164c251-ef97-4bf5-b8de-696a1f9e6b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fd239dea-93cd-4e4f-814e-46b274d0d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['computer', 'compute', 'computing', 'computation', 'computed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f4af8b85-72d8-4efa-9c4c-fc3537a0819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer  --  comput\n",
      "compute  --  comput\n",
      "computing  --  comput\n",
      "computation  --  comput\n",
      "computed  --  comput\n"
     ]
    }
   ],
   "source": [
    "for i in l:\n",
    "    print(i, ' -- ', stemmer.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ffdfb8ed-5950-44dc-9a78-9e272d469c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nlp_c('computer compute computing computation computed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "03ec3bd6-3d6a-4438-af68-43c3207fc708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer  --  computer\n",
      "compute  --  compute\n",
      "computing  --  computing\n",
      "computation  --  computation\n",
      "computed  --  compute\n"
     ]
    }
   ],
   "source": [
    "for i in l:\n",
    "    print(i, ' -- ', i.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ec095482-9b84-460a-bc81-e3d9fa5e07d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat  --  eat\n",
      "eats  --  eat\n",
      "eating  --  eat\n",
      "ate  --  eat\n",
      "hit  --  hit\n"
     ]
    }
   ],
   "source": [
    "l = nlp_c('eat eats eating ate hit')\n",
    "for i in l:\n",
    "    print(i, ' -- ', i.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed4d88d-8458-45d7-a260-64e271ee5cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shubham      | nsubj      | submitted \n",
      "submitted    | ROOT       | submitted \n",
      "his          | poss       | resignation\n",
      "resignation  | dobj       | submitted \n",
      "with         | prep       | submitted \n",
      "a            | det        | message   \n",
      "hilariously  | advmod     | honest    \n",
      "honest       | amod       | message   \n",
      "message      | pobj       | with      \n",
      ".            | punct      | submitted \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load a language model with parser enabled\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # This includes the parser\n",
    "\n",
    "# Input text\n",
    "text = \"Shubham submitted his resignation with a hilariously honest message.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print dependencies\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<12} | {token.dep_:<10} | {token.head.text:<10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae6d2e50-c1af-4611-94c8-a48858532162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Load English parser model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from IPython.core import display\n",
    "import IPython.display\n",
    "# Sample sentence\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2f20a93-ba26-4bec-92a4-3b56b69e0a0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'display' from 'IPython.core.display' (C:\\Users\\s_nas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\display.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m doc = nlp(text)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Display dependency tree in your browser\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mdisplacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdep\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjupyter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Set jupyter=False if using outside notebooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\spacy\\displacy\\__init__.py:69\u001b[39m, in \u001b[36mrender\u001b[39m\u001b[34m(docs, style, page, minify, jupyter, options, manual)\u001b[39m\n\u001b[32m     65\u001b[39m     html = RENDER_WRAPPER(html)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m jupyter \u001b[38;5;129;01mor\u001b[39;00m (jupyter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_in_jupyter()):\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# return HTML rendered by IPython display()\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# See #4840 for details on span wrapper to disable mathjax\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTML, display\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m display(HTML(\u001b[33m'\u001b[39m\u001b[33m<span class=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtex2jax_ignore\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m</span>\u001b[39m\u001b[33m'\u001b[39m.format(html)))\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m html\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'display' from 'IPython.core.display' (C:\\Users\\s_nas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\display.py)"
     ]
    }
   ],
   "source": [
    "text = \"Shubham submitted his resignation with a hilariously honest message.\"\n",
    "from IPython.display import display, HTML\n",
    "# Process the sentence\n",
    "doc = nlp(text)\n",
    "\n",
    "# Display dependency tree in your browser\n",
    "displacy.render(doc, style='dep', jupyter=True)  # Set jupyter=False if using outside notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9a9002-e876-468e-a643-b1022885a8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
